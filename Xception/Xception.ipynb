{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junyan/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from keras.applications.xception import preprocess_input as xception_preprocessor\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_v3_preprocessor\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = \"/Users/junyan/Downloads/Homework/DeepLearning/Project/data/labels.csv\"\n",
    "\n",
    "train_df = pd.read_csv(LABELS)\n",
    "\n",
    "top_breeds = sorted(list(train_df['breed'].value_counts().head(120).index))\n",
    "train_df = train_df[train_df['breed'].isin(top_breeds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "TRAIN_FOLDER = \"/Users/junyan/Downloads/Homework/DeepLearning/Project/data/train/\"\n",
    "TEST_FOLDER = \"/Users/junyan/Downloads/Homework/DeepLearning/Project/data/test/\"\n",
    "\n",
    "DIM = 299\n",
    "\n",
    "train_df['image_path'] = train_df.apply( lambda x: ( TRAIN_FOLDER + x[\"id\"] + \".jpg\" ), axis=1 )\n",
    "\n",
    "train_data = np.array([ img_to_array(load_img(img, target_size=(DIM, DIM))) for img in train_df['image_path'].values.tolist()]).astype('float32')\n",
    "train_labels = train_df['breed']\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(train_data, train_labels, test_size=0.2, stratify=np.array(train_labels), random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8177, 299, 299, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.get_dummies(y_train.reset_index(drop=True), columns=top_breeds).as_matrix()\n",
    "y_validation = pd.get_dummies(y_validation.reset_index(drop=True), columns=top_breeds).as_matrix()\n",
    "\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained model's weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kuszma.JPG.zip\r\n",
      "imagenet_class_index.json\r\n",
      "inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5.zip\r\n",
      "inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5.zip\r\n",
      "inception_v3_weights_tf_dim_ordering_tf_kernels.h5.zip\r\n",
      "inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5.zip\r\n",
      "resnet50_weights_tf_dim_ordering_tf_kernels.h5.zip\r\n",
      "resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5.zip\r\n",
      "vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5.zip\r\n",
      "xception_weights_tf_dim_ordering_tf_kernels.h5.zip\r\n",
      "xception_weights_tf_dim_ordering_tf_kernels_notop.h5.zip\r\n"
     ]
    }
   ],
   "source": [
    "from os import makedirs\n",
    "from os.path import expanduser, exists, join\n",
    "\n",
    "!ls /Users/junyan/Downloads/Homework/DeepLearning/Project/data/pretrained-model/\n",
    "\n",
    "cache_dir = expanduser(join('~', '.keras'))\n",
    "if not exists(cache_dir):\n",
    "    makedirs(cache_dir)\n",
    "models_dir = join(cache_dir, 'models')\n",
    "if not exists(models_dir):\n",
    "    makedirs(models_dir)\n",
    "    \n",
    "!cp /Users/junyan/Downloads/Homework/DeepLearning/Project/data/pretrained-model/*notop* ~/.keras/models/\n",
    "!cp /Users/junyan/Downloads/Homework/DeepLearning/Project/data/pretrained-model/imagenet_class_index.json ~/.keras/models/\n",
    "!cp /Users/junyan/Downloads/Homework/DeepLearning/Project/data/pretrained-model/resnet50* ~/.keras/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting : Xception\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 245,880\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/150\n",
      "8177/8177 [==============================] - 2s 223us/step - loss: 4.6404 - acc: 0.0525 - val_loss: 4.4067 - val_acc: 0.1746\n",
      "Epoch 2/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 4.2643 - acc: 0.2923 - val_loss: 4.0198 - val_acc: 0.5081\n",
      "Epoch 3/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 3.9053 - acc: 0.5626 - val_loss: 3.6473 - val_acc: 0.7183\n",
      "Epoch 4/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 3.5612 - acc: 0.6959 - val_loss: 3.2939 - val_acc: 0.7946\n",
      "Epoch 5/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 3.2348 - acc: 0.7561 - val_loss: 2.9592 - val_acc: 0.8328\n",
      "Epoch 6/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 2.9287 - acc: 0.7815 - val_loss: 2.6473 - val_acc: 0.8455\n",
      "Epoch 7/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 2.6446 - acc: 0.7992 - val_loss: 2.3609 - val_acc: 0.8582\n",
      "Epoch 8/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 2.3864 - acc: 0.8133 - val_loss: 2.1023 - val_acc: 0.8670\n",
      "Epoch 9/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 2.1540 - acc: 0.8211 - val_loss: 1.8733 - val_acc: 0.8758\n",
      "Epoch 10/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 1.9491 - acc: 0.8282 - val_loss: 1.6726 - val_acc: 0.8797\n",
      "Epoch 11/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 1.7708 - acc: 0.8336 - val_loss: 1.4992 - val_acc: 0.8797\n",
      "Epoch 12/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 1.6167 - acc: 0.8373 - val_loss: 1.3511 - val_acc: 0.8851\n",
      "Epoch 13/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 1.4848 - acc: 0.8413 - val_loss: 1.2248 - val_acc: 0.8875\n",
      "Epoch 14/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 1.3725 - acc: 0.8452 - val_loss: 1.1186 - val_acc: 0.8919\n",
      "Epoch 15/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 1.2769 - acc: 0.8479 - val_loss: 1.0279 - val_acc: 0.8944\n",
      "Epoch 16/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 1.1952 - acc: 0.8497 - val_loss: 0.9511 - val_acc: 0.8978\n",
      "Epoch 17/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 1.1251 - acc: 0.8514 - val_loss: 0.8856 - val_acc: 0.8983\n",
      "Epoch 18/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 1.0649 - acc: 0.8541 - val_loss: 0.8291 - val_acc: 0.8998\n",
      "Epoch 19/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 1.0127 - acc: 0.8564 - val_loss: 0.7808 - val_acc: 0.9012\n",
      "Epoch 20/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.9674 - acc: 0.8554 - val_loss: 0.7381 - val_acc: 0.9022\n",
      "Epoch 21/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.9274 - acc: 0.8578 - val_loss: 0.7017 - val_acc: 0.9017\n",
      "Epoch 22/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.8924 - acc: 0.8591 - val_loss: 0.6695 - val_acc: 0.9017\n",
      "Epoch 23/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.8611 - acc: 0.8602 - val_loss: 0.6409 - val_acc: 0.9042\n",
      "Epoch 24/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.8333 - acc: 0.8619 - val_loss: 0.6158 - val_acc: 0.9027\n",
      "Epoch 25/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.8082 - acc: 0.8622 - val_loss: 0.5931 - val_acc: 0.9027\n",
      "Epoch 26/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.7856 - acc: 0.8644 - val_loss: 0.5730 - val_acc: 0.9037\n",
      "Epoch 27/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.7650 - acc: 0.8658 - val_loss: 0.5550 - val_acc: 0.9042\n",
      "Epoch 28/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.7464 - acc: 0.8676 - val_loss: 0.5385 - val_acc: 0.9051\n",
      "Epoch 29/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.7293 - acc: 0.8676 - val_loss: 0.5235 - val_acc: 0.9037\n",
      "Epoch 30/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.7136 - acc: 0.8699 - val_loss: 0.5101 - val_acc: 0.9037\n",
      "Epoch 31/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.6991 - acc: 0.8715 - val_loss: 0.4977 - val_acc: 0.9051\n",
      "Epoch 32/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.6856 - acc: 0.8721 - val_loss: 0.4863 - val_acc: 0.9042\n",
      "Epoch 33/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.6732 - acc: 0.8733 - val_loss: 0.4759 - val_acc: 0.9042\n",
      "Epoch 34/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.6614 - acc: 0.8739 - val_loss: 0.4663 - val_acc: 0.9046\n",
      "Epoch 35/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.6506 - acc: 0.8746 - val_loss: 0.4574 - val_acc: 0.9056\n",
      "Epoch 36/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.6404 - acc: 0.8754 - val_loss: 0.4492 - val_acc: 0.9051\n",
      "Epoch 37/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.6308 - acc: 0.8762 - val_loss: 0.4415 - val_acc: 0.9066\n",
      "Epoch 38/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.6217 - acc: 0.8764 - val_loss: 0.4345 - val_acc: 0.9071\n",
      "Epoch 39/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.6132 - acc: 0.8771 - val_loss: 0.4278 - val_acc: 0.9086\n",
      "Epoch 40/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.6051 - acc: 0.8778 - val_loss: 0.4216 - val_acc: 0.9066\n",
      "Epoch 41/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.5974 - acc: 0.8783 - val_loss: 0.4157 - val_acc: 0.9066\n",
      "Epoch 42/150\n",
      "8177/8177 [==============================] - 0s 43us/step - loss: 0.5901 - acc: 0.8794 - val_loss: 0.4106 - val_acc: 0.9061\n",
      "Epoch 43/150\n",
      "8177/8177 [==============================] - 0s 45us/step - loss: 0.5831 - acc: 0.8800 - val_loss: 0.4054 - val_acc: 0.9051\n",
      "Epoch 44/150\n",
      "8177/8177 [==============================] - 0s 45us/step - loss: 0.5763 - acc: 0.8811 - val_loss: 0.4005 - val_acc: 0.9061\n",
      "Epoch 45/150\n",
      "8177/8177 [==============================] - 0s 45us/step - loss: 0.5700 - acc: 0.8822 - val_loss: 0.3959 - val_acc: 0.9042\n",
      "Epoch 46/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.5639 - acc: 0.8827 - val_loss: 0.3918 - val_acc: 0.9061\n",
      "Epoch 47/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.5582 - acc: 0.8831 - val_loss: 0.3875 - val_acc: 0.9071\n",
      "Epoch 48/150\n",
      "8177/8177 [==============================] - 0s 44us/step - loss: 0.5524 - acc: 0.8836 - val_loss: 0.3841 - val_acc: 0.9051\n",
      "Epoch 49/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.5471 - acc: 0.8846 - val_loss: 0.3802 - val_acc: 0.9056\n",
      "Epoch 50/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.5419 - acc: 0.8850 - val_loss: 0.3769 - val_acc: 0.9051\n",
      "Epoch 51/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.5367 - acc: 0.8860 - val_loss: 0.3734 - val_acc: 0.9042\n",
      "Epoch 52/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.5319 - acc: 0.8869 - val_loss: 0.3706 - val_acc: 0.9051\n",
      "Epoch 53/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.5272 - acc: 0.8871 - val_loss: 0.3675 - val_acc: 0.9046\n",
      "Epoch 54/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.5227 - acc: 0.8875 - val_loss: 0.3650 - val_acc: 0.9051\n",
      "Epoch 55/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.5182 - acc: 0.8885 - val_loss: 0.3621 - val_acc: 0.9042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.5140 - acc: 0.8892 - val_loss: 0.3594 - val_acc: 0.9042\n",
      "Epoch 57/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.5099 - acc: 0.8896 - val_loss: 0.3570 - val_acc: 0.9046\n",
      "Epoch 58/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.5059 - acc: 0.8905 - val_loss: 0.3548 - val_acc: 0.9046\n",
      "Epoch 59/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.5019 - acc: 0.8915 - val_loss: 0.3528 - val_acc: 0.9042\n",
      "Epoch 60/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.4981 - acc: 0.8923 - val_loss: 0.3504 - val_acc: 0.9051\n",
      "Epoch 61/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4945 - acc: 0.8924 - val_loss: 0.3485 - val_acc: 0.9051\n",
      "Epoch 62/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.4908 - acc: 0.8932 - val_loss: 0.3467 - val_acc: 0.9032\n",
      "Epoch 63/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.4873 - acc: 0.8935 - val_loss: 0.3448 - val_acc: 0.9046\n",
      "Epoch 64/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4839 - acc: 0.8940 - val_loss: 0.3429 - val_acc: 0.9056\n",
      "Epoch 65/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4805 - acc: 0.8941 - val_loss: 0.3415 - val_acc: 0.9061\n",
      "Epoch 66/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.4772 - acc: 0.8947 - val_loss: 0.3395 - val_acc: 0.9056\n",
      "Epoch 67/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4739 - acc: 0.8949 - val_loss: 0.3385 - val_acc: 0.9051\n",
      "Epoch 68/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4710 - acc: 0.8960 - val_loss: 0.3368 - val_acc: 0.9061\n",
      "Epoch 69/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4677 - acc: 0.8954 - val_loss: 0.3351 - val_acc: 0.9061\n",
      "Epoch 70/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4647 - acc: 0.8970 - val_loss: 0.3337 - val_acc: 0.9061\n",
      "Epoch 71/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4617 - acc: 0.8964 - val_loss: 0.3327 - val_acc: 0.9051\n",
      "Epoch 72/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4589 - acc: 0.8972 - val_loss: 0.3312 - val_acc: 0.9061\n",
      "Epoch 73/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4562 - acc: 0.8979 - val_loss: 0.3299 - val_acc: 0.9056\n",
      "Epoch 74/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.4534 - acc: 0.8985 - val_loss: 0.3288 - val_acc: 0.9051\n",
      "Epoch 75/150\n",
      "8177/8177 [==============================] - ETA: 0s - loss: 0.4524 - acc: 0.898 - 0s 38us/step - loss: 0.4507 - acc: 0.8991 - val_loss: 0.3276 - val_acc: 0.9056\n",
      "Epoch 76/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.4480 - acc: 0.9002 - val_loss: 0.3265 - val_acc: 0.9066\n",
      "Epoch 77/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4455 - acc: 0.9016 - val_loss: 0.3257 - val_acc: 0.9056\n",
      "Epoch 78/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4427 - acc: 0.9017 - val_loss: 0.3242 - val_acc: 0.9061\n",
      "Epoch 79/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4402 - acc: 0.9023 - val_loss: 0.3233 - val_acc: 0.9056\n",
      "Epoch 80/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4377 - acc: 0.9027 - val_loss: 0.3225 - val_acc: 0.9056\n",
      "Epoch 81/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4356 - acc: 0.9025 - val_loss: 0.3216 - val_acc: 0.9046\n",
      "Epoch 82/150\n",
      "8177/8177 [==============================] - ETA: 0s - loss: 0.4334 - acc: 0.904 - 0s 38us/step - loss: 0.4330 - acc: 0.9042 - val_loss: 0.3209 - val_acc: 0.9056\n",
      "Epoch 83/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4305 - acc: 0.9045 - val_loss: 0.3201 - val_acc: 0.9046\n",
      "Epoch 84/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4283 - acc: 0.9051 - val_loss: 0.3192 - val_acc: 0.9046\n",
      "Epoch 85/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4259 - acc: 0.9055 - val_loss: 0.3182 - val_acc: 0.9056\n",
      "Epoch 86/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4236 - acc: 0.9058 - val_loss: 0.3175 - val_acc: 0.9056\n",
      "Epoch 87/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4213 - acc: 0.9062 - val_loss: 0.3169 - val_acc: 0.9046\n",
      "Epoch 88/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4193 - acc: 0.9072 - val_loss: 0.3161 - val_acc: 0.9051\n",
      "Epoch 89/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4171 - acc: 0.9068 - val_loss: 0.3152 - val_acc: 0.9046\n",
      "Epoch 90/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.4149 - acc: 0.9077 - val_loss: 0.3147 - val_acc: 0.9042\n",
      "Epoch 91/150\n",
      "8177/8177 [==============================] - 0s 44us/step - loss: 0.4129 - acc: 0.9082 - val_loss: 0.3141 - val_acc: 0.9042\n",
      "Epoch 92/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.4108 - acc: 0.9088 - val_loss: 0.3138 - val_acc: 0.9042\n",
      "Epoch 93/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4087 - acc: 0.9089 - val_loss: 0.3131 - val_acc: 0.9042\n",
      "Epoch 94/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4068 - acc: 0.9106 - val_loss: 0.3125 - val_acc: 0.9046\n",
      "Epoch 95/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4048 - acc: 0.9105 - val_loss: 0.3119 - val_acc: 0.9046\n",
      "Epoch 96/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.4028 - acc: 0.9115 - val_loss: 0.3113 - val_acc: 0.9046\n",
      "Epoch 97/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.4008 - acc: 0.9117 - val_loss: 0.3108 - val_acc: 0.9042\n",
      "Epoch 98/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3990 - acc: 0.9121 - val_loss: 0.3102 - val_acc: 0.9046\n",
      "Epoch 99/150\n",
      "8177/8177 [==============================] - ETA: 0s - loss: 0.3968 - acc: 0.912 - 0s 39us/step - loss: 0.3971 - acc: 0.9122 - val_loss: 0.3096 - val_acc: 0.9046\n",
      "Epoch 100/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3953 - acc: 0.9135 - val_loss: 0.3092 - val_acc: 0.9042\n",
      "Epoch 101/150\n",
      "8177/8177 [==============================] - 0s 37us/step - loss: 0.3934 - acc: 0.9140 - val_loss: 0.3090 - val_acc: 0.9042\n",
      "Epoch 102/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3916 - acc: 0.9140 - val_loss: 0.3084 - val_acc: 0.9046\n",
      "Epoch 103/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3897 - acc: 0.9148 - val_loss: 0.3079 - val_acc: 0.9037\n",
      "Epoch 104/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3881 - acc: 0.9160 - val_loss: 0.3077 - val_acc: 0.9042\n",
      "Epoch 105/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3863 - acc: 0.9166 - val_loss: 0.3075 - val_acc: 0.9037\n",
      "Epoch 106/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3845 - acc: 0.9175 - val_loss: 0.3069 - val_acc: 0.9042\n",
      "Epoch 107/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.3828 - acc: 0.9177 - val_loss: 0.3062 - val_acc: 0.9042\n",
      "Epoch 108/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3812 - acc: 0.9176 - val_loss: 0.3062 - val_acc: 0.9032\n",
      "Epoch 109/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3795 - acc: 0.9179 - val_loss: 0.3057 - val_acc: 0.9046\n",
      "Epoch 110/150\n",
      "8177/8177 [==============================] - ETA: 0s - loss: 0.3817 - acc: 0.917 - 0s 39us/step - loss: 0.3779 - acc: 0.9189 - val_loss: 0.3055 - val_acc: 0.9037\n",
      "Epoch 111/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3763 - acc: 0.9203 - val_loss: 0.3052 - val_acc: 0.9037\n",
      "Epoch 112/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3746 - acc: 0.9209 - val_loss: 0.3047 - val_acc: 0.9042\n",
      "Epoch 113/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3730 - acc: 0.9211 - val_loss: 0.3045 - val_acc: 0.9046\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3715 - acc: 0.9221 - val_loss: 0.3041 - val_acc: 0.9037\n",
      "Epoch 115/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3699 - acc: 0.9217 - val_loss: 0.3042 - val_acc: 0.9037\n",
      "Epoch 116/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3684 - acc: 0.9221 - val_loss: 0.3037 - val_acc: 0.9042\n",
      "Epoch 117/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3669 - acc: 0.9227 - val_loss: 0.3036 - val_acc: 0.9037\n",
      "Epoch 118/150\n",
      "8177/8177 [==============================] - 0s 40us/step - loss: 0.3653 - acc: 0.9232 - val_loss: 0.3032 - val_acc: 0.9046\n",
      "Epoch 119/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3639 - acc: 0.9226 - val_loss: 0.3029 - val_acc: 0.9042\n",
      "Epoch 120/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3624 - acc: 0.9241 - val_loss: 0.3030 - val_acc: 0.9027\n",
      "Epoch 121/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3610 - acc: 0.9243 - val_loss: 0.3026 - val_acc: 0.9042\n",
      "Epoch 122/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3595 - acc: 0.9247 - val_loss: 0.3026 - val_acc: 0.9046\n",
      "Epoch 123/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3580 - acc: 0.9241 - val_loss: 0.3024 - val_acc: 0.9037\n",
      "Epoch 124/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3566 - acc: 0.9249 - val_loss: 0.3020 - val_acc: 0.9042\n",
      "Epoch 125/150\n",
      "8177/8177 [==============================] - 0s 39us/step - loss: 0.3552 - acc: 0.9259 - val_loss: 0.3019 - val_acc: 0.9042\n",
      "Epoch 126/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3538 - acc: 0.9264 - val_loss: 0.3016 - val_acc: 0.9037\n",
      "Epoch 127/150\n",
      "8177/8177 [==============================] - 0s 38us/step - loss: 0.3524 - acc: 0.9260 - val_loss: 0.3017 - val_acc: 0.9046\n",
      "Epoch 128/150\n",
      "8177/8177 [==============================] - 0s 43us/step - loss: 0.3511 - acc: 0.9269 - val_loss: 0.3011 - val_acc: 0.9046\n",
      "Epoch 129/150\n",
      "8177/8177 [==============================] - 0s 48us/step - loss: 0.3498 - acc: 0.9269 - val_loss: 0.3014 - val_acc: 0.9042\n",
      "Epoch 130/150\n",
      "8177/8177 [==============================] - 0s 44us/step - loss: 0.3485 - acc: 0.9277 - val_loss: 0.3010 - val_acc: 0.9042\n",
      "Epoch 131/150\n",
      "8177/8177 [==============================] - 0s 44us/step - loss: 0.3472 - acc: 0.9283 - val_loss: 0.3011 - val_acc: 0.9027\n",
      "Epoch 132/150\n",
      "8177/8177 [==============================] - 0s 43us/step - loss: 0.3458 - acc: 0.9287 - val_loss: 0.3009 - val_acc: 0.9046\n",
      "Epoch 133/150\n",
      "8177/8177 [==============================] - ETA: 0s - loss: 0.3458 - acc: 0.928 - 0s 46us/step - loss: 0.3446 - acc: 0.9287 - val_loss: 0.3008 - val_acc: 0.9037\n",
      "Epoch 134/150\n",
      "8177/8177 [==============================] - 0s 43us/step - loss: 0.3432 - acc: 0.9296 - val_loss: 0.3007 - val_acc: 0.9032\n",
      "Epoch 135/150\n",
      "8177/8177 [==============================] - 0s 43us/step - loss: 0.3420 - acc: 0.9302 - val_loss: 0.3004 - val_acc: 0.9042\n",
      "Epoch 136/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.3408 - acc: 0.9300 - val_loss: 0.3005 - val_acc: 0.9042\n",
      "Epoch 137/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.3396 - acc: 0.9302 - val_loss: 0.3003 - val_acc: 0.9042\n",
      "Epoch 138/150\n",
      "8177/8177 [==============================] - 0s 41us/step - loss: 0.3383 - acc: 0.9308 - val_loss: 0.3001 - val_acc: 0.9042\n",
      "Epoch 139/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.3370 - acc: 0.9309 - val_loss: 0.3001 - val_acc: 0.9042\n",
      "Epoch 140/150\n",
      "8177/8177 [==============================] - 0s 44us/step - loss: 0.3360 - acc: 0.9313 - val_loss: 0.3001 - val_acc: 0.9032\n",
      "Epoch 141/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.3347 - acc: 0.9310 - val_loss: 0.2996 - val_acc: 0.9046\n",
      "Epoch 142/150\n",
      "8177/8177 [==============================] - 0s 44us/step - loss: 0.3335 - acc: 0.9320 - val_loss: 0.3001 - val_acc: 0.9046\n",
      "Epoch 143/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.3323 - acc: 0.9321 - val_loss: 0.3000 - val_acc: 0.9042\n",
      "Epoch 144/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.3312 - acc: 0.9324 - val_loss: 0.2998 - val_acc: 0.9027\n",
      "Epoch 145/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.3301 - acc: 0.9326 - val_loss: 0.2997 - val_acc: 0.9046\n",
      "Epoch 146/150\n",
      "8177/8177 [==============================] - 0s 43us/step - loss: 0.3289 - acc: 0.9329 - val_loss: 0.2998 - val_acc: 0.9032\n",
      "Epoch 147/150\n",
      "8177/8177 [==============================] - 0s 43us/step - loss: 0.3278 - acc: 0.9335 - val_loss: 0.2998 - val_acc: 0.9046\n",
      "Epoch 148/150\n",
      "8177/8177 [==============================] - 0s 43us/step - loss: 0.3266 - acc: 0.9332 - val_loss: 0.2997 - val_acc: 0.9037\n",
      "Epoch 149/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.3255 - acc: 0.9337 - val_loss: 0.2994 - val_acc: 0.9037\n",
      "Epoch 150/150\n",
      "8177/8177 [==============================] - 0s 42us/step - loss: 0.3244 - acc: 0.9338 - val_loss: 0.2997 - val_acc: 0.9042\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    #\"InceptionV3\": {\n",
    "    #    \"model\": InceptionV3,\n",
    "    #    \"preprocessor\": inception_v3_preprocessor,\n",
    "    #    \"input_shape\": (299,299,3),\n",
    "    #    \"seed\": 1234,\n",
    "    #    \"pooling\": \"avg\"\n",
    "    #},\n",
    "    \"Xception\": {\n",
    "        \"model\": Xception,\n",
    "        \"preprocessor\": xception_preprocessor,\n",
    "        \"input_shape\": (299,299,3),\n",
    "        \"seed\": 5512,\n",
    "        \"pooling\": \"avg\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(\"Predicting : {}\".format(model_name))\n",
    "    filename = model_name + '_features.npy'\n",
    "    validfilename = model_name + '_validfeatures.npy'\n",
    "    if exists(filename):\n",
    "        features = np.load(filename)\n",
    "        validation_features = np.load(validfilename)\n",
    "    else:\n",
    "        #image propocessing:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                zoom_range = 0.3,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1)\n",
    "        validation_datagen = ImageDataGenerator()\n",
    "        \n",
    "\n",
    "        # Use pretrained model to generate Bottleneck Features:\n",
    "        Xception_model = Xception(weights='imagenet', include_top=False, input_shape = (299,299,3), pooling=\"avg\")\n",
    "        \n",
    "        train_datagen.preprocessing_function = xception_preprocessor\n",
    "        train_generator = train_datagen.flow(x_train, y_train, shuffle=False, batch_size=batch_size, seed = 5512)\n",
    "        features = Xception_model.predict_generator(train_generator,verbose=1)\n",
    "        \n",
    "        validation_datagen.preprocessing_function = xception_preprocessor\n",
    "        validation_generator = validation_datagen.flow(x_validation, y_validation, shuffle=False, batch_size=batch_size, seed = 5512)\n",
    "        validation_features = Xception_model.predict_generator(validation_generator,verbose=1)\n",
    "        \n",
    "        np.save(filename, features)\n",
    "        np.save(validfilename, validation_features)\n",
    "        \n",
    "      \n",
    "    \n",
    "    # Bulid top layers:\n",
    "    inputs = Input(shape=(2048,))\n",
    "    #x = Dense(256, activation='relu')(inputs)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    predictions = Dense(120, activation='softmax')(inputs)\n",
    "    \n",
    "    model_top = Model(inputs = inputs, outputs = predictions)\n",
    "    model_top.summary()\n",
    "    \n",
    "    model_top.compile(optimizer = Adam(0.0001), \n",
    "                      loss = categorical_crossentropy, \n",
    "                      metrics = ['accuracy'])\n",
    "    \n",
    "    # Train the top model:\n",
    "    model_top.fit(features, y_train,\n",
    "                batch_size=256, epochs=150, verbose=1, \n",
    "                validation_data=(validation_features, y_validation))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load testing data and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10357/10357 [00:40<00:00, 256.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "#loading test images\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "TEST_FOLDER = '/Users/junyan/Downloads/Homework/DeepLearning/Project/data/sample_submission.csv'\n",
    "test_data = pd.read_csv(TEST_FOLDER)\n",
    "\n",
    "x_test = []\n",
    "for i in tqdm(test_data['id'].values):\n",
    "    img = cv2.imread('/Users/junyan/Downloads/Homework/DeepLearning/Project/data/test/{}.jpg'.format(i))\n",
    "    x_test.append(cv2.resize(img, (299, 299)))\n",
    "    \n",
    "x_test = np.array(x_test, np.float32)\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testfilename = 'Xception_testfeatures.npy'\n",
    "if exists(testfilename):\n",
    "        test_features = np.load(testfilename)\n",
    "else:\n",
    "    test_datagen = ImageDataGenerator()\n",
    "    test_datagen.preprocessing_function = xception_preprocessor\n",
    "    test_generator = test_datagen.flow(x_test, shuffle=False, batch_size=batch_size, seed = 5512)\n",
    "    test_features = Xception_model.predict_generator(test_generator, verbose=1)\n",
    "    np.save('Xception_testfeatures.npy', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 120)\n"
     ]
    }
   ],
   "source": [
    "predictions = model_top.predict(test_features)\n",
    "print predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating Kaggle upload file\n",
    "df_train = pd.read_csv('/Users/junyan/Downloads/Homework/DeepLearning/Project/data/labels.csv')\n",
    "targets_series = df_train['breed']\n",
    "one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 121)\n"
     ]
    }
   ],
   "source": [
    "#generating Kaggle upload file\n",
    "test_DF = pd.read_csv('/Users/junyan/Downloads/Homework/DeepLearning/Project/data/sample_submission.csv')\n",
    "sub = pd.DataFrame(predictions)\n",
    "col_names = one_hot.columns.values\n",
    "sub.columns = col_names\n",
    "sub.insert(0, 'id', test_DF['id'])\n",
    "sub.head(5)\n",
    "print(sub.shape)\n",
    "sub.to_csv('Xception_sub2.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
